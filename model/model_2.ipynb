{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated=pd.read_csv(\"text_with_vectors_3.csv\")\n",
    "X=df_updated['vector']\n",
    "y=df_updated['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.array([np.fromstring(vec.strip('[]'), sep=' ') for vec in X_train])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_test= np.array([np.fromstring(vec.strip('[]'), sep=' ') for vec in X_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.to_numpy()\n",
    "X_test=X_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(-1, 1)  # Reshape if it's missing a second dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 1.3331 - accuracy: 0.5322 - val_loss: 1.0252 - val_accuracy: 0.6350\n",
      "Epoch 2/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.0477 - accuracy: 0.6204 - val_loss: 0.9650 - val_accuracy: 0.6540\n",
      "Epoch 3/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.9748 - accuracy: 0.6386 - val_loss: 0.9266 - val_accuracy: 0.6557\n",
      "Epoch 4/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.9293 - accuracy: 0.6475 - val_loss: 0.9184 - val_accuracy: 0.6392\n",
      "Epoch 5/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.8981 - accuracy: 0.6530 - val_loss: 0.8943 - val_accuracy: 0.6435\n",
      "Epoch 6/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.8690 - accuracy: 0.6551 - val_loss: 0.8565 - val_accuracy: 0.6582\n",
      "Epoch 7/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.8541 - accuracy: 0.6554 - val_loss: 0.8456 - val_accuracy: 0.6574\n",
      "Epoch 8/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.8391 - accuracy: 0.6566 - val_loss: 0.8376 - val_accuracy: 0.6492\n",
      "Epoch 9/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.8330 - accuracy: 0.6565 - val_loss: 0.8436 - val_accuracy: 0.6494\n",
      "Epoch 10/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.8191 - accuracy: 0.6597 - val_loss: 0.8223 - val_accuracy: 0.6562\n",
      "Epoch 11/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.8104 - accuracy: 0.6595 - val_loss: 0.8115 - val_accuracy: 0.6569\n",
      "Epoch 12/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.8100 - accuracy: 0.6587 - val_loss: 0.8220 - val_accuracy: 0.6497\n",
      "Epoch 13/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.8043 - accuracy: 0.6611 - val_loss: 0.8037 - val_accuracy: 0.6605\n",
      "Epoch 14/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.8021 - accuracy: 0.6616 - val_loss: 0.8110 - val_accuracy: 0.6550\n",
      "Epoch 15/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.7984 - accuracy: 0.6607 - val_loss: 0.8019 - val_accuracy: 0.6530\n",
      "Epoch 16/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.7978 - accuracy: 0.6611 - val_loss: 0.8113 - val_accuracy: 0.6542\n",
      "Epoch 17/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.7990 - accuracy: 0.6579 - val_loss: 0.8023 - val_accuracy: 0.6596\n",
      "Epoch 18/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.7990 - accuracy: 0.6601 - val_loss: 0.8694 - val_accuracy: 0.6103\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.8019 - accuracy: 0.6530\n",
      "Test Accuracy: 0.65\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(128, input_shape=(X_train.shape[1],), activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Dense(3, activation='softmax')  # Output layer for 3 classes\n",
    "])\n",
    "\n",
    "# Compile the model with a reduced learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005),  \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train the model with class weights and fewer epochs\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=50,  # Reduced from 100 to 30\n",
    "                    batch_size=64, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"modelv0.0.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
